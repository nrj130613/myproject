{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrj130613/myproject/blob/main/NER_pos_window_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zal6A26yDN2f"
      },
      "source": [
        "# Bigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyoh28LtDN2h"
      },
      "source": [
        "# 1. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jivk7RHLcfs5",
        "outputId": "a61ccd13-e8aa-4ee8-af72-7082ca920278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.9/dist-packages (from sklearn-crfsuite) (4.65.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from sklearn-crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sklearn-crfsuite) (1.16.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn-crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1LHZe1etwxaKnP6TWTbDscasBe5pGykjJ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsNUsIdla17i",
        "outputId": "6b968658-0e36-4d11-fd30-de8d9c7b3f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LHZe1etwxaKnP6TWTbDscasBe5pGykjJ\n",
            "To: /content/train_auto_tok.tsv\n",
            "100% 38.9M/38.9M [00:00<00:00, 129MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_yMUtkhDN2u",
        "outputId": "b0411b33-e739-4ddb-8b05-aee2c5226bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ธรรมนูญ\tB_PER\n",
            "แชมป์\tO\n",
            "สิงห์\tO\n",
            "คลาสสิก\tO\n",
            "กวาด\tO\n",
            "รางวัล\tO\n",
            "แสน\tO\n",
            "สี่\tO\n",
            "หมื่น\tO\n",
            "บาท\tO\n"
          ]
        }
      ],
      "source": [
        "!head train_auto_tok.tsv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1LtdB8q2xVhK7vivJxTU6yYnl3KTG-QGS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3X5dFX_fakH",
        "outputId": "6b15f2e7-51af-46b2-bd86-870b730d35da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LtdB8q2xVhK7vivJxTU6yYnl3KTG-QGS\n",
            "To: /content/dev_auto_tok.tsv\n",
            "\r  0% 0.00/3.56M [00:00<?, ?B/s]\r100% 3.56M/3.56M [00:00<00:00, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_name):\n",
        "    with open(file_name, 'r') as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    X, Y = [], []\n",
        "    sentence, labels = [], []\n",
        "    for line in lines:\n",
        "        if not line:\n",
        "            if sentence:\n",
        "                X.append(sentence)\n",
        "                Y.append(labels)\n",
        "                sentence, labels = [], []\n",
        "        else:\n",
        "            word, tag = line.split('\\t')\n",
        "            sentence.append(word)\n",
        "            labels.append(tag)\n",
        "    if sentence:\n",
        "        X.append(sentence)\n",
        "        Y.append(labels)\n",
        "\n",
        "    return (X, Y)\n"
      ],
      "metadata": {
        "id": "KpLjfGPwv9pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCAI5im4fm8G"
      },
      "outputs": [],
      "source": [
        "Xtrain, Ytrain = load_data('train_auto_tok.tsv')\n",
        "Xtest, Ytest = load_data('dev_auto_tok.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzNGTg4aDN27"
      },
      "outputs": [],
      "source": [
        "import sklearn_crfsuite\n",
        "import sklearn_crfsuite.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aocgHCXiNuR"
      },
      "source": [
        "# 2. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_jiAHYnkbuF",
        "outputId": "df900b39-6e53-435d-9355-471e79ceb5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-4.0.0-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.9/dist-packages (from pythainlp) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->pythainlp) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->pythainlp) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->pythainlp) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->pythainlp) (3.4)\n",
            "Installing collected packages: pythainlp\n",
            "Successfully installed pythainlp-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Features\n"
      ],
      "metadata": {
        "id": "5Cp8iT8rlarE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pythainlp\n",
        "from pythainlp.tag import pos_tag\n",
        "\n",
        "def pos_tagging(sentences):\n",
        "  sents_pos = []\n",
        "  for i in range(len(sentences)):\n",
        "    #for sent in sentences[i]:\n",
        "    each_sent_pos = pos_tag(sentences[i])\n",
        "\n",
        "    sents_pos.append(each_sent_pos)\n",
        "  return sents_pos"
      ],
      "metadata": {
        "id": "L1bcNGlUNkUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pos_tagging(Xtrain[0:5])\n",
        "test"
      ],
      "metadata": {
        "id": "8noBt5R4SD_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def featurize(sent, window_size):\n",
        "    feature_seq = []\n",
        "    for i in range(len(sent)):\n",
        "        word, pos = sent[i]\n",
        "        features = {}\n",
        "        features[\"{}_{}_pos\".format(word, i)] = pos\n",
        "        # position features\n",
        "        #features['bias'] = 1.0\n",
        "        #features['pos'] = i\n",
        "        #features['pos_inv'] = len(sent) - i\n",
        "        # bigram word window feature\n",
        "        for j in range(1, window_size + 1):\n",
        "            if i - j >= 0:\n",
        "                features['prev_word_{}'.format(j)] = sent[i-j][1]\n",
        "            if i + j < len(sent):\n",
        "                features['next_word_{}'.format(j)] = sent[i+j][1]\n",
        "            if i - j >= 0 and i + j < len(sent):\n",
        "                features['conjunctive_{}'.format(j)] = sent[i-j][0] + '_' + word + '_' + sent[i+j][0]\n",
        "\n",
        "        features['token_{}'.format(word, i)] = word.isdigit()\n",
        "\n",
        "        feature_seq.append(features)\n",
        "    return feature_seq\n"
      ],
      "metadata": {
        "id": "enlgNdidzKKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[1]"
      ],
      "metadata": {
        "id": "5lXPTfW8uzHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featurize(test[1], 2)"
      ],
      "metadata": {
        "id": "TBUcgzUnV9b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcJrivsrktwa"
      },
      "source": [
        "# 3. Train and evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_pos = pos_tagging(Xtrain[0:5000])\n",
        "test_set_pos = pos_tagging(Xtest)"
      ],
      "metadata": {
        "id": "mIxaZQstXbEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn_crfsuite"
      ],
      "metadata": {
        "id": "JO5UnW0migCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import CRF, metrics\n",
        "\n",
        "def train_and_evaluate(Xtrain, Ytrain, Xtest, Ytest):\n",
        "    X_train_feats = [featurize(sent, 2) for sent in Xtrain]\n",
        "    X_test_feats = [featurize(sent, 2) for sent in Xtest]\n",
        "    crf = CRF()\n",
        "    crf.fit(X_train_feats, Ytrain)\n",
        "    y_pred = crf.predict(X_test_feats)\n",
        "    #f1_score = metrics.flat_f1_score(Ytest, y_pred, average='weighted', labels=crf.classes_, zero_division=1)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "U2MUp0cmAaP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = Xtest[0:5000]"
      ],
      "metadata": {
        "id": "Vdlet-8SC97Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = train_and_evaluate(train_set_pos, Ytrain[0:5000], test_set_pos, Ytest)"
      ],
      "metadata": {
        "id": "D2LJru15AhCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "zx_e85CeCQYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "for i in range(len(Xtest)):\n",
        "    each = list(zip(Xtest[i], y_pred[i]))\n",
        "    predicted.append(each)"
      ],
      "metadata": {
        "id": "iFnzLqhhAzom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "id": "GYLKsm_cCVdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(sentence):\n",
        "\n",
        "    entities = []\n",
        "    entity_sofar = []\n",
        "    type_sofar = None\n",
        "    tokens = []\n",
        "    for token, ner_tag in sentence:\n",
        "        tokens.append(token)\n",
        "        if ner_tag[0] == 'B':\n",
        "            if type_sofar is not None:\n",
        "                entities.append((type_sofar, ''.join(entity_sofar)))\n",
        "                entity_sofar = []\n",
        "                type_sofar = None\n",
        "            if len(ner_tag) > 1:\n",
        "                _, tag = ner_tag.split('_')\n",
        "                type_sofar = tag\n",
        "                entity_sofar.append(token)\n",
        "            else:\n",
        "                type_sofar = 'MISC'\n",
        "                entity_sofar.append(token)\n",
        "\n",
        "        elif ner_tag[0] == 'I':\n",
        "            if len(ner_tag) > 1:\n",
        "                _, tag = ner_tag.split('_')\n",
        "                type_sofar = tag\n",
        "            entity_sofar.append(token)\n",
        "        elif ner_tag[0] == 'E':\n",
        "            entity_sofar.append(token)\n",
        "            entities.append((type_sofar, ''.join(entity_sofar)))\n",
        "            entity_sofar = []\n",
        "            type_sofar = None\n",
        "        elif ner_tag == 'O':\n",
        "            if len(entity_sofar) != 0:\n",
        "                entities.append((type_sofar, ''.join(entity_sofar)))\n",
        "                entity_sofar = []\n",
        "                type_sofar = None\n",
        "    return entities\n",
        "    #return ''.join(tokens), [(t, x) for t, x in entities if t is not None]\n"
      ],
      "metadata": {
        "id": "KNSXLp9IA3es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_list = list(map(extract_entities, predicted))\n",
        "print(len(output_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NztlkqUPA-NP",
        "outputId": "01af15e1-2250-42cc-99d7-0eaa76f147af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json.dump(output_list, open('pos_test11111.json', encoding='utf8', mode='w'))"
      ],
      "metadata": {
        "id": "zqcpneH5BEj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "def train_and_evaluate(Xtrain, Ytrain, Xtest, Ytest):\n",
        "    X_train_feats = [featurize(sent, 2) for sent in Xtrain]\n",
        "    X_test_feats = [featurize(sent, 2) for sent in Xtest]\n",
        "    crf = sklearn_crfsuite.CRF()\n",
        "    crf.fit(X_train_feats, Ytrain)\n",
        "    y_pred = crf.predict(X_test_feats)\n",
        "    f1_score = metrics.flat_f1_score(Ytest, y_pred, average='weighted', labels=crf.classes_, zero_division=1)\n",
        "    return f1_score"
      ],
      "metadata": {
        "id": "beirnUjLS-w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(train_set_pos, Ytrain[0:5000], test_set_pos, Ytest[0:60000])"
      ],
      "metadata": {
        "id": "Y5PpK3btTF8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89d2341-edf0-4c97-d0b6-2457c0471e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8610347083464913"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trigram"
      ],
      "metadata": {
        "id": "spgqF3NR1veU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn_crfsuite"
      ],
      "metadata": {
        "id": "zOzbJchy13Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "def train_and_evaluate_tri(Xtrain, Ytrain, Xtest, Ytest):\n",
        "    X_train_feats = [featurize(sent, 3) for sent in Xtrain]\n",
        "    X_test_feats = [featurize(sent, 3) for sent in Xtest]\n",
        "    crf = sklearn_crfsuite.CRF()\n",
        "    crf.fit(X_train_feats, Ytrain)\n",
        "    y_pred = crf.predict(X_test_feats)\n",
        "    f1_score = metrics.flat_f1_score(Ytest, y_pred, average='weighted', labels=crf.classes_, zero_division=1)\n",
        "    return f1_score"
      ],
      "metadata": {
        "id": "mBUNhpAj14zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_tri(train_set_pos, Ytrain[0:60000], test_set_pos, Ytest[0:60000])"
      ],
      "metadata": {
        "id": "FSDzZXhp153M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iCPuLSfZif1-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}