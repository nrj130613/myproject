# -*- coding: utf-8 -*-
"""base trigram model contest

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_8O0iOqOZzTfP-E2q6aZ800ctVaVh9ls

# LOAD DATA
"""

!pip install --upgrade --no-cache-dir gdown

!gdown 1RF697A7FCVvdbYtXGrmzupq04FluQh_f

"""test set"""

!gdown 17rntxqy9vPR-Z3kPEC64j6AtwTXKCazI

!gdown 17upH5GLwuKJ3sZEzW0Zzdz63bkKw_V8Y

import pandas as pd
test_data = pd.read_csv('test_set_no_answer.csv')

test_data

import pandas as pd
data = pd.read_csv('dev_set.csv')

data

test_context = test_data['context'].to_list()
first_letters = test_data['first letter'].to_list()
#dev_ans = data['answer'].to_list()

"""#TRIGRAM"""

from collections import Counter

with open('train.src.tok', 'r') as f:
    training_data = f.read().split('\n')

sentences = [s.split(' ') for s in training_data[:2000000]]

counter = {}

for tokens in sentences:
    for i in range(len(tokens)- 3 - 1):
      context = tuple(tokens[i:(i+3-1)])
      word = tokens[(i+3-1)]
      if context not in counter:
        counter[context] = Counter()
      counter[context][word] += 1

context_list = []
for sentence in test_context:
  tk = sentence.split()
  ct = tuple(tk[-2:])
  context_list.append(ct)

pred_word = []

for i in range(len(context_list)):
    if context_list[i] not in counter:
        pred_word.append('')
        continue

    counters = counter[context_list[i]].most_common()
    for word, count in counters:
        if word[0] == first_letters[i]:
            pred_word.append(word)
            break
    else:
        pred_word.append('')

pred_word

def accuracy(true_labels, predicted_labels):
    """
    Computes the accuracy of predicted labels given the true labels.

    Args:
        true_labels (list): A list of true labels.
        predicted_labels (list): A list of predicted labels.

    Returns:
        float: The accuracy of predicted labels, as a percentage.
    """
    correct_count = 0
    for i in range(len(true_labels)):
        if true_labels[i] == predicted_labels[i]:
            correct_count += 1
    acc = correct_count / len(true_labels) * 100
    return acc

acc = accuracy(dev_ans, pred_word)
print(f"Accuracy: {acc:.2f}%")

"""#4-gram"""

from collections import Counter

with open('train.src.tok', 'r') as f:
    training_data = f.read().split('\n')

sentences4g = [s.split(' ') for s in training_data[:500000]]

counter = {}

for tokens in sentences4g:
    for i in range(len(tokens)-4-1):
        context = tuple(tokens[i:(i+4-1)])
        word = tokens[(i+4-1)]
        if context not in counter:
            counter[context] = Counter()
        counter[context][word] += 1

context_list = []
for sentence in dev_context:
  tk = sentence.split()
  ct = tuple(tk[-3:])
  context_list.append(ct)

pred_word_4g = []

for i in range(len(context_list)):
    if context_list[i] not in counter:
        pred_word_4g.append('')
        continue

    counters = counter[context_list[i]].most_common()
    for word, count in counters:
        if word[0] == first_letters[i]:
            pred_word_4g.append(word)
            break
    else:
        pred_word_4g.append('')

pred_word_4g

def accuracy(true_labels, predicted_labels):
    """
    Computes the accuracy of predicted labels given the true labels.

    Args:
        true_labels (list): A list of true labels.
        predicted_labels (list): A list of predicted labels.

    Returns:
        float: The accuracy of predicted labels, as a percentage.
    """
    correct_count = 0
    for i in range(len(true_labels)):
        if true_labels[i] == predicted_labels[i]:
            correct_count += 1
    acc = correct_count / len(true_labels) * 100
    return acc

acc = accuracy(dev_ans, pred_word_4g)
print(f"Accuracy: {acc:.2f}%")